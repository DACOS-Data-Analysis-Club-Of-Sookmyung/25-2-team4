{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONDIC0kjlGCn",
        "outputId": "1a214da5-7b01-42b6-c4f6-195cc2ea502a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 데이터셋 텍스트화"
      ],
      "metadata": {
        "id": "XBe59nVFjhzI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- user.jsonl"
      ],
      "metadata": {
        "id": "GBs_42vTo8Kr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0KzTyyzh8Wd"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "INPUT_PATH = \"/content/drive/MyDrive/user.jsonl\"\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/user_textified.jsonl\"\n",
        "\n",
        "def safe_join(items):\n",
        "    \"\"\"리스트가 비어있거나 None이면 빈 문자열 반환\"\"\"\n",
        "    if not items:\n",
        "        return \"\"\n",
        "    return \", \".join(items)\n",
        "\n",
        "with open(INPUT_PATH, \"r\", encoding=\"utf-8\") as fin, \\\n",
        "     open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as fout:\n",
        "\n",
        "    for line in fin:\n",
        "        user = json.loads(line)\n",
        "        user_id = user.get(\"user_id\")\n",
        "        student_num = user.get(\"student_num\")\n",
        "        name = user.get(\"name\")\n",
        "        profile = user.get(\"profile\", {})\n",
        "        history = user.get(\"history\", [])\n",
        "        bio = profile.get(\"bio\", \"\")\n",
        "        history_descs = [\n",
        "            h.get(\"desc\", \"\")\n",
        "            for h in history\n",
        "            if h.get(\"desc\")\n",
        "        ]\n",
        "\n",
        "        u_text = \" \".join([bio] + history_descs).strip()\n",
        "\n",
        "        skills = profile.get(\"skills\", [])\n",
        "        u_skill = f\"skills: {safe_join(skills)}\"\n",
        "\n",
        "        prefer_role = user.get(\"prefer_role\", \"\")\n",
        "        u_role = f\"preferred role: {prefer_role}\"\n",
        "\n",
        "        majors = profile.get(\"major\", [])\n",
        "        interests = profile.get(\"interests\", [])\n",
        "\n",
        "        u_interest = (\n",
        "            f\"major: {safe_join(majors)} \"\n",
        "            f\"interests: {safe_join(interests)}\"\n",
        "        ).strip()\n",
        "\n",
        "        output = {\n",
        "            \"user_id\": user_id,\n",
        "            \"student_num\": student_num,\n",
        "            \"name\": name,\n",
        "            \"u_text\": u_text,\n",
        "            \"u_skill\": u_skill,\n",
        "            \"u_role\": u_role,\n",
        "            \"u_interest\": u_interest\n",
        "        }\n",
        "\n",
        "        fout.write(json.dumps(output, ensure_ascii=False) + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- project.jsonl"
      ],
      "metadata": {
        "id": "979gv03_pDQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "INPUT_PATH = \"/content/drive/MyDrive/project.jsonl\"\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/project_textified.jsonl\"\n",
        "\n",
        "\n",
        "def safe_join(items):\n",
        "    \"\"\"리스트가 비어있거나 None이면 빈 문자열 반환\"\"\"\n",
        "    if not items:\n",
        "        return \"\"\n",
        "    return \", \".join(items)\n",
        "\n",
        "\n",
        "def normalize_text(x):\n",
        "    if isinstance(x, list):\n",
        "        return \". \".join(s.strip() for s in x if s.strip())\n",
        "    if isinstance(x, str):\n",
        "        return x.strip()\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "with open(INPUT_PATH, \"r\", encoding=\"utf-8\") as fin, \\\n",
        "     open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as fout:\n",
        "\n",
        "    for line in fin:\n",
        "        project = json.loads(line)\n",
        "\n",
        "        project_id = project.get(\"project_id\")\n",
        "        deadline = project.get(\"deadline\")\n",
        "\n",
        "        title = normalize_text(project.get(\"p_title\"))\n",
        "        desc = normalize_text(project.get(\"p_dis\"))\n",
        "\n",
        "        if desc:\n",
        "            p_text = f\"{title}. {desc}\"\n",
        "        else:\n",
        "            p_text = title\n",
        "\n",
        "        skills = project.get(\"p_skill\", [])\n",
        "        p_skill = f\"required skills: {safe_join(skills)}\"\n",
        "\n",
        "        roles = project.get(\"p_role\", [])\n",
        "        p_role = f\"required roles: {safe_join(roles)}\"\n",
        "\n",
        "        fields = project.get(\"p_field\", [])\n",
        "        p_field = f\"project fields: {safe_join(fields)}\"\n",
        "\n",
        "        output = {\n",
        "            \"project_id\": project_id,\n",
        "            \"p_text\": p_text,\n",
        "            \"p_skill\": p_skill,\n",
        "            \"p_role\": p_role,\n",
        "            \"p_field\": p_field,\n",
        "            \"deadline\": deadline\n",
        "        }\n",
        "\n",
        "        fout.write(json.dumps(output, ensure_ascii=False) + \"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "v_0G9cKipC-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 데이터셋 구축"
      ],
      "metadata": {
        "id": "tjqgyV4btQFO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 기본 환경 설정"
      ],
      "metadata": {
        "id": "cVgepmvBthuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai faiss-cpu numpy tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSPgGZGK9TSP",
        "outputId": "40911088-393e-4d5e-e827-216115c933c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.12.0)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.13.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import faiss\n",
        "from tqdm import tqdm\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "BurV713CBSnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=)"
      ],
      "metadata": {
        "id": "5z_bAJoyBQp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 함수 정의"
      ],
      "metadata": {
        "id": "uAorona3BpzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# jsonl 로드 함수\n",
        "def load_jsonl(path):\n",
        "    data = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            data.append(json.loads(line))\n",
        "    return data"
      ],
      "metadata": {
        "id": "j2XJRVfbBqPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# openai 임베딩 함수 (배치)\n",
        "def embed_texts(texts, model=\"text-embedding-3-small\", batch_size=100):\n",
        "    embeddings = []\n",
        "\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i:i+batch_size]\n",
        "\n",
        "        response = client.embeddings.create(\n",
        "            model=model,\n",
        "            input=batch\n",
        "        )\n",
        "\n",
        "        embeddings.extend([r.embedding for r in response.data])\n",
        "\n",
        "    return np.array(embeddings, dtype=\"float32\")"
      ],
      "metadata": {
        "id": "mYkqRqcYB4ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- L2 정규화"
      ],
      "metadata": {
        "id": "cFR0_GMuCKKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def l2_normalize(vectors):\n",
        "    norms = np.linalg.norm(vectors, axis=1, keepdims=True)\n",
        "    return vectors / norms"
      ],
      "metadata": {
        "id": "q46mMbZgCLq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- FAISS index 생성, 저장"
      ],
      "metadata": {
        "id": "wekq78FECW-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_faiss_index(vectors, index_path):\n",
        "    dim = vectors.shape[1]\n",
        "    index = faiss.IndexFlatIP(dim)  # cosine similarity\n",
        "    index.add(vectors)\n",
        "    faiss.write_index(index, index_path)\n",
        "    return index"
      ],
      "metadata": {
        "id": "Dh6cIyzMCaTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###project_textified → index 생성"
      ],
      "metadata": {
        "id": "86M9NKMFCgId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project_data = load_jsonl(\"/content/drive/MyDrive/Contentbased/project_textified.jsonl\")\n",
        "\n",
        "views = {\n",
        "    \"text\": \"p_text\",\n",
        "    \"skill\": \"p_skill\",\n",
        "    \"role\": \"p_role\",\n",
        "    \"field\": \"p_field\"\n",
        "}\n",
        "\n",
        "project_ids = [p[\"project_id\"] for p in project_data]\n",
        "\n",
        "id_map = {}   # index → project_id\n",
        "indexes = {}  # view → faiss index\n",
        "\n",
        "for view, col in views.items():\n",
        "    texts = [p[col] for p in project_data]\n",
        "\n",
        "    embeddings = embed_texts(texts)\n",
        "    embeddings = l2_normalize(embeddings)\n",
        "\n",
        "    index_path = f\"/content/drive/MyDrive/Contentbased/project_{view}.index\"\n",
        "    index = build_faiss_index(embeddings, index_path)\n",
        "\n",
        "    indexes[view] = index\n",
        "    id_map[view] = project_ids\n",
        "\n",
        "    print(f\"[DONE] {view} index saved → {index_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JygCTPaXClq-",
        "outputId": "ff4fe7f9-f5a2-4391-d549-9cbc5ff11a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DONE] text index saved → /content/drive/MyDrive/Contentbased/project_text.index\n",
            "[DONE] skill index saved → /content/drive/MyDrive/Contentbased/project_skill.index\n",
            "[DONE] role index saved → /content/drive/MyDrive/Contentbased/project_role.index\n",
            "[DONE] field index saved → /content/drive/MyDrive/Contentbased/project_field.index\n"
          ]
        }
      ]
    }
  ]
}